import numpy as np
from MPS import MPS
from rnn import Circuit
import tensorflow as tf
import itertools as it
import sys

def flip2(S,O,K,site):
    Ns = S.shape[0]
    N  = S.shape[1]
    # variable with the  flipped the measurements generated by a 2-qubit p_gate
    flipped = np.repeat(S,K**2,axis=0) # repeat the samples K**2 sites 
    a = (np.array(list(it.product(range(K), repeat = 2)),dtype=np.uint8)) # possible combinations of outcomes on 2 qubits
    #replacing the outcomes with the possible flipped outcomes
    flipped[:,site[0]] = np.tile(a[:,0],(Ns)) 
    flipped[:,site[1]] = np.tile(a[:,1],(Ns)) 
    #getting the coefficients of the p-gates that accompany the flipped samples
    Coef = O[:,:,S[:,site[0]],S[:,site[1]]] 
    #Coef = O[S[:,site[0]],S[:,site[1]],:,:]  
    Coef  = np.reshape(np.transpose(Coef[:,:,:],(2,0,1)),(Ns*K**2)) # reshapes so that both Coef and flipped have the same dim
    # transform samples to one hot vector
    flipped = np.squeeze(np.reshape(np.eye(K)[flipped],[flipped.shape[0],N*K]).astype(np.uint8))
    #print(np.count_nonzero(np.abs(Coef) > 0.00000000001),Coef.shape[0], np.count_nonzero(np.abs(Coef) > 0.00000000001)/Nsamples)
    return flipped, Coef

def flip1(S,O,K,site):
    Ns = S.shape[0]
    N  = S.shape[1]
    # variable with the  flipped the measurements generated by a 1-qubit p_gate
    flipped = np.repeat(S,K,axis=0) # repeat the samples K**2 sites 
    a = (np.array(list(it.product(range(K), repeat = 1)),dtype=np.uint8)) # possible combinations of outcomes on 2 qubits
    #replacing the outcomes with the possible flipped outcomes
    flipped[:,site[0]] = np.tile(a[:,0],(Ns))
    #getting the coefficients of the p-gates that accompany the flipped samples
    Coef = O[:,S[:,site[0]]]
    Coef  = np.reshape(np.transpose(Coef),(Ns*K)) # reshapes so that both Coef and flipped have the same dim
    # transform samples to one hot vector
    flipped = np.squeeze(np.reshape(np.eye(K)[flipped],[flipped.shape[0],N*K]).astype(np.uint8))
    #print(np.count_nonzero(np.abs(Coef) > 0.00000000001),Coef.shape[0], np.count_nonzero(np.abs(Coef) > 0.00000000001)/Nsamples)
    return flipped, Coef


j_init = int(sys.argv[1])


Nqubits = 2
initial_product_state = '0'
#model
lat_rep = 1
gru_hid = 10
# training parameters
Nsamples = 100  # number of samples used in the estimation of the gradient 
Ndataset = 500000
epochs = 50 # How many times do we do gradient update per gate application

# model and POVM
POVM = "4Pauli"
circ = Circuit(povm=POVM, Number_qubits=Nqubits, latent_rep_size=lat_rep, gru_hidden=gru_hid, decoder='TimeDistributed_mol', Nsamples=Nsamples,init_state=initial_product_state)

mps = MPS(POVM=POVM,Number_qubits=Nqubits,MPS='GHZ')

a = (np.array(list(it.product(range(circ.K), repeat = 2)),dtype=np.uint8))

saver = tf.train.Saver()


#with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
with tf.Session() as sess:
    if j_init == 0:
        sess.run(tf.global_variables_initializer())
    else: 
        saver.restore(sess, "./models/model_site_"+str(j_init-1)+".ckpt")
        print("Model restored.")


    # GHZ state preparation 
    # H on the first qubit

    # Get the dataset
    if Ndataset != 0:
        Ncalls = Ndataset /Nsamples
        y0 =  np.zeros((Nsamples,circ.K))
        samples,lP = sess.run([circ.sample_RNN,circ.logP],feed_dict={circ.y0: y0})
        lP =np.reshape(lP,[-1,1])    

        for k in range(int(Ncalls)):
            y0 =  np.zeros((Nsamples,circ.K))
            sa,llpp = sess.run([circ.sample_RNN,circ.logP],feed_dict={circ.y0: y0})
            #print(sa)
            samples = np.vstack((samples,sa))
            llpp =np.reshape(llpp,[-1,1])
            lP =  np.vstack((lP,llpp))

    nsteps = int(samples.shape[0] / Nsamples)
    bcount = 0
    counter=0
    ept=np.random.permutation(samples)
    for i in range(epochs):
        #print("epoch", i,"out of ", epochs,"H gate on qubit 0",)
        for idx in range(nsteps):
            if bcount*circ.batchsize+ circ.batchsize>=Ndataset:
                bcount=0
                ept=np.random.permutation(samples)

            batch=ept[ bcount*circ.batchsize: bcount*circ.batchsize+circ.batchsize,:]
            bcount=bcount+1

            sites=[0]
             
            flip,Coef = flip1(batch,circ.povm.p_single_qubit[0],circ.K,sites)


            #print "step and alpha valule ", epoch, counter, alpha
            _, gen_loss = sess.run((circ.optimizer,  circ.cost),
                           feed_dict={circ.flip_2: flip, circ.co_2:Coef, circ.gtype: 1})
            
            print(gen_loss,0,flush=True)
            counter = counter+1

            
            # classical fidelity
             

        #print(0,i,gen_loss)      
    #save_path = saver.save(sess, "./models/model_site_"+str(j)+".ckpt")

 

    for j in range(j_init,Nqubits-1):
        sites=[j,j+1]
        #print(sites)
        # generating the "dataset" 
        if Ndataset != 0:
           Ncalls = Ndataset /Nsamples
           y0 =  np.zeros((Nsamples,circ.K))    
           samples,lP = sess.run([circ.sample_RNN,circ.logP],feed_dict={circ.y0: y0})
           lP =np.reshape(lP,[-1,1])

           for k in range(int(Ncalls)):
               y0 =  np.zeros((Nsamples,circ.K))
               sa,llpp = sess.run([circ.sample_RNN,circ.logP],feed_dict={circ.y0: y0})
               #print(sa)
               samples = np.vstack((samples,sa))
               llpp =np.reshape(llpp,[-1,1])
               lP =  np.vstack((lP,llpp))

        nsteps = int(samples.shape[0] / Nsamples)
        bcount = 0
        counter = 0 
        ept = np.random.permutation(samples)
        for i in range(epochs):
            #print("epoch", i,"out of ", epochs,"site", j)
            for idx in range(nsteps):
                if bcount*circ.batchsize+ circ.batchsize>=Ndataset:
                    bcount=0
                    ept=np.random.permutation(samples)

                batch = ept[ bcount*circ.batchsize: bcount*circ.batchsize+circ.batchsize,:]
                bcount = bcount+1

                
                flip,Coef = flip2(batch,circ.povm.p_two_qubit[0],circ.K,sites)
                

                #print "step and alpha valule ", epoch, counter, alpha
                _, gen_loss = sess.run((circ.optimizer,  circ.cost),
                           feed_dict={circ.flip_2: flip, circ.co_2:Coef, circ.gtype: 2})
                print(gen_loss,j+1,flush=True) #print(gen_loss)
                counter = counter+1 
            #print(j+1,(j+1)*epochs+i,gen_loss)
        save_path = saver.save(sess, "./models/model_site_"+str(j)+".ckpt")
          
         

    if Ndataset != 0:
        Ncalls = Ndataset /Nsamples
        y0 =  np.zeros((Nsamples,circ.K)) 
        samples,lP = sess.run([circ.sample_RNN,circ.logP],feed_dict={circ.y0: y0})
        lP =np.reshape(lP,[-1,1])

        for k in range(int(Ncalls)):
            sa,llpp = sess.run([circ.sample_RNN,circ.logP],feed_dict={circ.y0: y0})
            samples = np.vstack((samples,sa))
            llpp =np.reshape(llpp,[-1,1])
            lP =  np.vstack((lP,llpp))

        # classical fidelity
        cFid, cFidError, KL, KLError = mps.cFidelity(samples,lP)
        Fid, FidErrorr = mps.Fidelity(samples)
        stabilizers,sError = mps.stabilizersGHZ_samples(samples)
        print(cFid, cFidError, KL, KLError,Fid, FidErrorr)
        print(stabilizers,sError,np.mean(stabilizers),np.mean(sError))
        np.savetxt("fidelity.txt",np.array([cFid, cFidError, KL, KLError,Fid, FidErrorr,np.mean(stabilizers),np.mean(sError)]),newline=" ")
        c = np.concatenate((stabilizers,sError),axis=0) 
        np.savetxt("stabilizers.txt",c,newline=" ")



