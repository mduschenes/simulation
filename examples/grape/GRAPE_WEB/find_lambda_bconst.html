
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
      <title>Filename : find_lambda_bconst</title>
      <meta name="generator" content="MATLAB 7.14">
      <link rel="schema.DC" href="http://purl.org/dc/elements/1.1/">
      <meta name="DC.date" content="2014-03-05">
      <meta name="DC.source" content="find_lambda_bconst.m">
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
      <link rel="stylesheet" type="text/css" href="css/screen.css" media="screen" />
  </head>
  
  <body>
    <ul id=menu>
      <li><a href="flowchart.html">Flow Chart</a>
      <li><a href="tools/tools.html">Tools</a>
      <li><a href="faq/faq.html">F. A. Q.</a>
      <li><a href="../index.html">NMR-QIP Page</a>
    </ul>
    <div class="content">
    <h1>FileName : find_lambda_bconst</h1>
    <h2>Contents</h2>
    <div><ul><li><a href="#1">Description</a></li></ul></div><h2>Description<a name="1"></a></h2>
    
    <p>We make use of conjugate gradients instead of gradients, which improves the GRAPE. See this <a href="http://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf" target="blank">link</a> for more information on conjugate gradients. There are many forms of them we have used Polard-Ribiere formula (See Colm Ryan PhD thesis for more details).</p>
    <p>The gradient is modified such that it have information about the previous gradient steps. In the following, gra.gr(:,:,i) = <img src="Images\find_lambda_bconst_eq50568.png" alt="$\Delta_i$"> represents gradient of <img src="Images\find_lambda_bconst_eq79464.png" alt="$i^{th}$"> step calculated according to N Khaneja's GRAPE paper. The conjugate gradient <img src="Images\find_lambda_bconst_eq41012.png" alt="$\lambda_i$"> for <img src="Images\find_lambda_bconst_eq79464.png" alt="$i^{th}$"> step inturn is calculated by the following formula (Polard-Ribiere) :</p>
    <p><img src="Images\find_lambda_bconst_eq58433.png" alt="$\lambda_i = \Delta_i + \beta_i \lambda_{i-1}$"></p>
    <p><img src="Images\find_lambda_bconst_eq79022.png" alt="$$\beta_i=\frac{\Delta_i^T(\Delta_i-\Delta_{i-1})}{||\Delta_{i-1}||^2}$$"></p>
    <p>In the following bet = <img src="Images\find_lambda_bconst_eq42727.png" alt="$\beta$">, and gra.lambda = <img src="Images\find_lambda_bconst_eq23351.png" alt="$\lambda$">.</p>
    <p>For <img src="Images\find_lambda_bconst_eq66045.png" alt="$1^{st}$"> iteration <img src="Images\find_lambda_bconst_eq32633.png" alt="$\beta_1=0$"> i.e. <img src="Images\find_lambda_bconst_eq49148.png" alt="$\lambda_1 = \Delta_1$">. We also reset the <img src="Images\find_lambda_bconst_eq42727.png" alt="$\beta$"> to zero when the fidelity is not increasing more than <img src="Images\find_lambda_bconst_eq69486.png" alt="$10^{-8}$"> in the subsequent iteration.</p>
    
    <pre class="codeinput">
    <span class="keyword">function</span> lambda = find_lambda_bconst(iter)
    <span class="keyword">global</span> gra

    gra.gr(:,:,iter)=gra.af;
    bet=0;

    <span class="keyword">if</span> (iter == 1)
	gra.lambda(:,:,1)=gra.gr(:,:,1);
    <span class="keyword">else</span>
	<span class="keyword">if</span> ((gra.F(iter)-gra.F(iter-1))&lt;1e-8)
	    bet=0;
	<span class="keyword">else</span>
	    bet=sum(sum(gra.gr(:,:,iter).*(gra.gr(:,:,iter)-gra.gr(:,:,iter-1))))/sum(sum(gra.gr(:,:,iter-1).^2));
	    bet=max(0,bet);
	<span class="keyword">end</span>
	gra.lambda(:,:,iter)=gra.gr(:,:,iter) + bet*gra.lambda(:,:,iter-1);
    <span class="keyword">end</span>

    lambda=gra.lambda(:,:,iter);
    </pre><p class="footer"><br>
	  Published with MATLAB&reg; 7.14<br></p>
</div>
</body>
</html>